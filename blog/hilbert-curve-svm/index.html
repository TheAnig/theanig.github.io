<!doctype html><html data-theme=light lang=en xmlns=http://www.w3.org/1999/xhtml><head><meta charset=UTF-8><meta content="This is my own personal corner of the internet" name=description><meta content="width=device-width,initial-scale=1" name=viewport><meta content=#00bf63 name=theme-color><title>Using Fractals for feature extraction in image classification tasks - TheAnig</title><link href=https://theanig.github.io/blog/hilbert-curve-svm/ rel=canonical><link href=https://theanig.github.io/favicon.png rel=icon type=image/png><link href=https://theanig.github.io/apple-touch-icon.png rel=apple-touch-icon sizes=180x180 type=image/png><link title="TheAnig - RSS Feed" href=https://theanig.github.io/rss.xml rel=alternate type=application/rss+xml><link title="TheAnig - Atom Feed" href=https://theanig.github.io/atom.xml rel=alternate type=application/atom+xml><style>:root{--accent-color:#00bf63}</style><link href=https://theanig.github.io/style.css rel=stylesheet><link href=https://theanig.github.io/katex.css rel=stylesheet><script defer src=https://theanig.github.io/closable.js></script><script defer src=https://theanig.github.io/copy-button.js></script><script data-goatcounter=https://stats.theanig.dev/count defer src=https://theanig.github.io/count.js></script><script defer src=https://theanig.github.io/katex.min.js></script><script defer src=https://theanig.github.io/auto-render.min.js></script><script defer src=https://theanig.github.io/katex-init.js></script><script defer src=https://theanig.github.io/elasticlunr.min.js></script><script defer src=https://theanig.github.io/search-elasticlunr.js></script><meta content=TheAnig property=og:site_name><meta content="Using Fractals for feature extraction in image classification tasks - TheAnig" property=og:title><meta content=https://theanig.github.io/blog/hilbert-curve-svm/ property=og:url><meta content="Fractals have always fascinated mathematicians, scientists, and even artists. Their self-similar, infinitely intricate structures open up a world of possibilities for practical applications. One such application, as I’ve been exploring, involves using fractals—specifically the Hilbert curve—for feature extraction in image classification. This blog post dives into how this method works, its philosophical roots, and the fascinating mathematical concepts that make it all possible." property=og:description><meta content=https://theanig.github.io/card.png property=og:image><meta content=en_US property=og:locale><body><div id=handle></div><header id=site-nav><nav><a href=#main-content tabindex=0> Skip to Main Content </a><ul><li id=home><a href=https://theanig.github.io> <i class=icon></i>TheAnig</a><li class=divider><li><a href=https://theanig.github.io/blog/>Blog</a><li id=search><button class=circle id=search-toggle title=Search><i class=icon></i></button><li id=theme-switcher><details class=closable><summary class=circle title=Theme><i class=icon></i></summary> <ul><li><button title="Switch to Light Theme" class=circle id=theme-light><i class=icon></i></button><li><button title="Switch to Dark Theme" class=circle id=theme-dark><i class=icon></i></button><li><button title="Use System Theme" class=circle id=theme-system><i class=icon></i></button></ul></details><li id=feed><details class=closable><summary class=circle title=Feed><i class=icon></i></summary> <ul><li><a href=https://theanig.github.io/rss.xml>RSS</a><li><a href=https://theanig.github.io/atom.xml>Atom</a></ul></details></ul></nav><div id=search-container><label class=visually-hidden for=search-bar>Search</label><input placeholder="Search for…" autocomplete=off disabled id=search-bar type=search><div id=search-results-container><div id=search-results></div></div></div></header><main id=main-content><article><div id=heading><p><small> <time datetime=" 2018-12-06T00:00:00+00:00">Published on December 06, 2018</time></small><h1>Using Fractals for feature extraction in image classification tasks</h1><ul class=tags><li><a class=tag href=https://theanig.github.io/tags/machine-learning/>machine-learning</a><li><a class=tag href=https://theanig.github.io/tags/data-processing/>data-processing</a><li><a class=tag href=https://theanig.github.io/tags/image-classification/>image-classification</a><li><a class=tag href=https://theanig.github.io/tags/deep-learning/>deep-learning</a><li><a class=tag href=https://theanig.github.io/tags/hilbert-curves-project/>hilbert-curves-project</a></ul></div><div id=buttons-container><details class=closable id=toc><summary title="Table of Contents"><i class=icon></i></summary> <div><strong class=title>Table of Contents</strong><div><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#introduction-rethinking-feature-extraction-with-fractals>Introduction: Rethinking Feature Extraction with Fractals</a><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#fractals-a-brief-overview>Fractals: A brief overview</a><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#space-filling-curves-and-practical-applications>Space-Filling Curves and Practical Applications</a><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#bridging-infinite-and-finite-realities>Bridging Infinite and Finite Realities</a></ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#fractals-in-feature-extraction-the-proposed-methodology>Fractals in Feature Extraction: The Proposed Methodology</a><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#from-pixels-to-frequencies-bridging-the-dimensions>From Pixels to Frequencies: Bridging the Dimensions</a></ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#comparing-space-filling-curves>Comparing Space Filling Curves</a><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#the-z-curve>The Z-Curve</a><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#peano-curve>Peano Curve</a><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#hilbert-curve>Hilbert Curve</a></ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#implementation>Implementation</a><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#the-process-of-hilbertification>The Process of Hilbertification</a><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#wavelet-transforms-for-feature-localization-and-compression>Wavelet Transforms for Feature Localization and Compression</a></ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#experimentation>Experimentation</a><ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#results-of-the-proposed-method>Results of the Proposed Method</a></ul><li><a href=https://theanig.github.io/blog/hilbert-curve-svm/#conclusions>Conclusions</a></ul></div></div></details><a title="Go to Top" href=#top id=go-to-top><i class=icon></i></a><a href="https://shareopenly.org/share/?url=https://theanig.github.io/blog/hilbert-curve-svm/&text=Fractals%20have%20always%20fascinated%20mathematicians%2C%20scientists%2C%20and%20even%20artists.%20Their%20self-similar%2C%20infinitely%20intricate%20structures%20open%20up%20a%20world%20of%20possibilities%20for%20practical%20applications.%20One%20such%20application%2C%20as%20I%E2%80%99ve%20been%20exploring%2C%20involves%20using%20fractals%E2%80%94specifically%20the%20Hilbert%20curve%E2%80%94for%20feature%20extraction%20in%20image%20classification.%20This%20blog%20post%20dives%20into%20how%20this%20method%20works%2C%20its%20philosophical%20roots%2C%20and%20the%20fascinating%20mathematical%20concepts%20that%20make%20it%20all%20possible." id=share title=Share><i class=icon></i></a><a title="File an Issue" href=https://github.com/TheAnig/theanig.github.io/issues id=issue><i class=icon></i></a></div><blockquote class=caution><p class=alert-title><i class=icon></i>Caution<ul><li>explain wavelet transforms<li>rearrange hilberts curve in the explanationor the article</ul></blockquote><h2 id=introduction-rethinking-feature-extraction-with-fractals>Introduction: Rethinking Feature Extraction with Fractals</h2><p>Feature extraction is at the core of image classification, a task that has seen groundbreaking advancements thanks to convolutional neural networks (CNNs). These models have revolutionized computer vision by leveraging spatial coherence to extract patterns, enabling machines to distinguish cats from dogs, recognize handwritten digits, and even detect tumors in medical scans. However, as powerful as CNNs are, they come with limitations—particularly their reliance on convolution operations, which are heavily tuned for two-dimensional data.<p>What if there were an alternative to convolutions? One that could preserve spatial relationships while offering a fresh perspective on how we process and interpret image data? Enter fractals, the infinitely complex, self-replicating structures that bridge mathematics and nature. In this blog post, I’ll explore how fractal geometry, specifically the Hilbert curve, can provide a novel approach to feature extraction.<p>This method reimagines image processing by transforming pixel data into a dense, one-dimensional representation using fractal-based mappings. Unlike traditional techniques, it takes advantage of the Hilbert curve’s ability to preserve locality and scale across resolutions, making it ideal for compact, efficient feature representation. Combined with wavelet transforms, which localize features in the frequency domain, this fractal-based approach opens up exciting possibilities for image classification and beyond.<h2 id=fractals-a-brief-overview>Fractals: A brief overview</h2><p>A fractal is an abstract object used to describe and simulate naturally occurring objects. The proper definition of a fractal, at least as Mandelbrot wrote it, is a shape whose “Hausdorff dimension” is greater than its “topological dimension”. Topological dimension is something that’s always an integer, wherein (loosely speaking) curve-ish things are 1-dimensional, surface-ish things are two-dimensional, etc. For example, a Koch Curve has topological dimension 1, and Hausdorff dimension 1.262. A rough surfaces might have topological dimension 2, but fractal dimension 2.3. And if a curve with topological dimension 1 has a Hausdorff dimension that happens to be exactly 2, or 3, or 4, etc., it would be considered a fractal, even though it’s fractal dimension is an integer.<p>For purposes of my method we can simplify our view of fractal as essentially a never-ending pattern. But even under fractals, there is a special set of self-similar fractals. These are rendered by repeating a simple process. The interesting property about fractals is that they exist in non-whole number dimensions, as discussed above (The Hausdorff dimension). This property is super-useful as this means that they effectively encode information from a non-primary dimension, a fact that was used extensively for lossy image compression.<p>We can use to our advantage this property to capture spatial, temporal or higher dimensional relation- ships in form of useful features that can be localized. (Using something like a Fourier transform or as in our case, wavelet transform)<h2 id=space-filling-curves-and-practical-applications>Space-Filling Curves and Practical Applications</h2><p>Before diving into the technicalities, let’s talk about space-filling curves. These are mathematical constructions that, despite their counterintuitive nature, are immensely useful. A space-filling curve is a line that weaves through every point in a two-dimensional (or higher-dimensional) space. One famous example is the Hilbert curve, which can be visualized as a fractal that becomes progressively more intricate at higher resolutions.<h3 id=bridging-infinite-and-finite-realities>Bridging Infinite and Finite Realities</h3><p>Space-filling curves address a philosophical question central to mathematics: How can results based on infinite concepts be useful in our finite world? The Hilbert curve provides a fascinating answer. It starts as a theoretical construct, existing in an infinite, continuous mathematical space. But its finite approximations—pseudo-Hilbert curves—serve practical purposes, such as translating images into sound or encoding spatial information into dense, one-dimensional representations.<figure><img alt="Example of a fractal" src=mandelbrot_set.jpg><figcaption>The Mandelbrot set: its boundary is a fractal curve with Hausdorff dimension 2. Courtesy of Wikipedia</figcaption></figure><p>Let me illustrate with an example: Imagine developing a device that helps people “see with their ears.” The device takes data from a camera, translates it into sound, and lets users interpret spatial information through auditory cues. In this setup, the Hilbert curve provides a way to map 2D image data (pixels) into a 1D frequency space, preserving spatial relationships between pixels while creating a coherent auditory representation.<h2 id=fractals-in-feature-extraction-the-proposed-methodology>Fractals in Feature Extraction: The Proposed Methodology</h2><p>Fractals, with their self-similar and infinitely intricate structures, provide a powerful framework for extracting meaningful features from complex datasets like images <sup class=footnote-reference id=fr-2-1><a href=#fn-2>[1]</a></sup>. The goal is to transform 2D image data into a dense, 1D representation that preserves spatial relationships and is optimized for computational efficiency. This section breaks down the methodology into three key components: mapping pixels to frequencies, employing the Hilbert curve for serialization, and leveraging wavelet transforms for localization and compression.<h3 id=from-pixels-to-frequencies-bridging-the-dimensions>From Pixels to Frequencies: Bridging the Dimensions</h3><p>At the heart of the method is the challenge of mapping two-dimensional pixel data to a one-dimensional frequency domain. Each pixel is associated with a frequency, and its intensity determines the loudness of that frequency in the resulting signal. This transformation enables image data to be represented as a superposition of frequencies, much like a musical composition where different instruments (frequencies) contribute to the overall sound <sup class=footnote-reference id=fr-1-1><a href=#fn-1>[2]</a></sup>.<p>The challenge lies in ensuring that this mapping preserves spatial coherence. Pixels that are close together in the original image should remain close in the frequency representation <sup class=footnote-reference id=fr-3-1><a href=#fn-3>[3]</a></sup>. This is critical for maintaining the integrity of spatial relationships, which are often key to successful image classification. Without this coherence, the resulting representation would lose its ability to accurately capture the structure of the original image.<h2 id=comparing-space-filling-curves>Comparing Space Filling Curves</h2><p>Space-filling curves provide a structured way to map multi-dimensional data into one-dimensional representations while attempting to preserve spatial locality. However, not all space-filling curves are created equal. When choosing a curve for applications like image feature extraction, it’s crucial to evaluate their performance in preserving spatial relationships. Let’s compare three popular curves: the Z-curve, the Peano curve, and the Hilbert curve. <sup class=footnote-reference id=fr-7-1><a href=#fn-7>[4]</a></sup><h3 id=the-z-curve>The Z-Curve</h3><aside><img alt="Example of a Z curve" src=zcurve.png></aside> The Z-curve, or Morton order, follows a zig-zag pattern that makes it simple to implement but poor at preserving spatial relationships. In 2D, the Z-curve introduces significant gaps, with many adjacent points in the sequence mapping to coordinates that are far apart in the original space. This results in an average displacement for unit edges exceeding 1.6 in 2D and 1.35 in higher dimensions, making it unsuitable for applications requiring strong locality preservation. <h3 id=peano-curve>Peano Curve</h3><aside><img alt="Example of a Peano curve" src=peano.png></aside> The Peano curve, in contrast, is much better at maintaining spatial coherence. By mapping scalar unit lengths in 1D to unit Euclidean lengths in 2D, it ensures that horizontal segments are exactly one unit long, although vertical segments can stretch to 2 or 5 units, slightly raising the average displacement. The Peano curve also achieves asymptotic stability at higher ranks, with its performance aligning closely with the Hilbert curve as resolution increases. <h3 id=hilbert-curve>Hilbert Curve</h3><aside><img alt="Example of a Hilbert curve" src=hilbert256.png></aside> Hilbert curve stands out as the best option for preserving locality. Its recursive, self-similar structure ensures that adjacent points in the sequence remain as close as possible in the original space, outperforming the Peano curve in both horizontal and vertical coherence. The Hilbert curve also scales well to higher dimensions, maintaining its locality-preserving properties regardless of resolution. Studies such as Color-Space Dimension Reduction and Bongki 2001 consistently rate the Hilbert curve as the superior choice, edging out the Peano curve in overall performance. <h2 id=implementation>Implementation</h2><p>To achieve a mapping that preserves spatial relationships, I turn to the Hilbert curve, a type of fractal known as a space-filling curve. The Hilbert curve provides an elegant solution to the problem of mapping 2D space to 1D space while preserving locality. Here’s why it’s so effective:<ol><li><p>Locality Preservation: Points that are close together on the Hilbert curve are also close together in the 2D image. This ensures that nearby pixels are mapped to nearby frequencies, preserving spatial coherence.</p><li><p>Scalability: The Hilbert curve is recursive and self-similar, meaning it can scale to any resolution. Whether the image is 256x256 or 512x512 pixels, the curve adapts seamlessly, providing a consistent framework for feature extraction.</p><li><p>Stability Across Resolutions: As the resolution of an image increases, the points on the Hilbert curve move less and less. This stability is crucial for applications where the resolution may change over time, such as progressive updates to image datasets or hierarchical processing pipelines.</p></ol><h3 id=the-process-of-hilbertification>The Process of Hilbertification</h3><aside><img alt="Example of a Hilbert Curve" src=hilbert-curve-anim.gif> Animation showing Hilbert Curve spanning an image of various resolutions. Courtesy of Wikipedia</aside> Hilbertification refers to the process of mapping an image’s pixel data to a 1D representation using the Hilbert curve. Here’s how it works: <ol><li><p>Divide the Image into Quadrants: The Hilbert curve starts by dividing the image into smaller regions, or quadrants, and defining a path that traverses each quadrant in a specific order.</p><li><p>Recursive Subdivision: Each quadrant is further subdivided into smaller grids, with the Hilbert curve path becoming increasingly intricate. This process repeats until the curve has visited every pixel in the image.</p><li><p>Generate a 1D Sequence: The final result is a 1D sequence of pixel intensities, where the order of the pixels reflects the traversal path of the Hilbert curve. This sequence forms the input for subsequent signal processing steps.</p></ol><h3 id=wavelet-transforms-for-feature-localization-and-compression>Wavelet Transforms for Feature Localization and Compression</h3><p>After Hilbertification, the next step is to apply wavelet transforms, which are mathematical tools for analyzing signals at multiple scales. Unlike Fourier transforms, which only provide frequency information, wavelet transforms capture both frequency and spatial (or temporal) information, making them ideal for feature extraction in images.<figure><img alt="Example of a Continuous Wavelet Transform" src=Continuous_wavelet_transform.gif><figcaption>Animation showing how wavelet transforms work. Courtesy of Wikipedia</figcaption></figure><h2 id=experimentation>Experimentation</h2><p>Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. The advantages of support vector machines are that they are effective in high dimensional spaces, still effective in cases where number of dimensions is greater than the number of samples, use a subset of training points in the decision function (called support vectors), so it is also memory efficient and versatile due to them supporting different Kernel functions which can be specified for the decision function. <sup class=footnote-reference id=fr-5-1><a href=#fn-5>[5]</a></sup> This was then followed by hilbertification, which is the process of serializing the image to the frequency domain as discussed earlier. This was then passed onto for localization. The fundamental idea of wavelet transforms is that the transformation should allow only changes in time extension, but not shape, this means that it encapsulates a denser representation of our signal on the time domain such that it preserves the spatial relationships as changes in the time extension are expected to conform to the corresponding analysis frequency of the basis function <sup class=footnote-reference id=fr-6-1><a href=#fn-6>[6]</a></sup>. This gives us a more dense set of features which is 1/4 the size of the original image.<figure><img alt="A Sample of the Data Used, before and after the proposed hilbertification method" src=hilbert_diagram.svg><figcaption>A Sample of the Data Used, before and after the proposed hilbertification method</figcaption></figure><p>Table below gives an overview of how my proposed method performs. Note that for my tests I had taken the entire image as a baseline. Apart from the documented results show below, I have also compared my method to cosine-transformed version of the dataset, in which case the result of the cosine-transformed classifiers were abnormally low so I decided to not publish those as it maybe due to my own faulty implementation I had also tried CIFAR-10 dataset, since that dataset is a color dataset, I did not get time to properly implement the method for the dataset.<h3 id=results-of-the-proposed-method>Results of the Proposed Method</h3><table><thead><tr><th>Dataset<th>Method<th>Linear SVM<th>RBF Kernel<th>Polynomial Kernel<tbody><tr><td><strong>Fashion MNIST</strong><td>Hilbertified<td>87.273<td>88.275<td>87.991<tr><td><td>Baseline<td>91.493<td>89.917<td>91.584<tr><td><strong>MNIST</strong><td>Hilbertified<td>96.026<td>96.535<td>97.134<tr><td><td>Baseline<td>98.318<td>98.661<td>99.288</table><h2 id=conclusions>Conclusions</h2><p>In order to reduce the number of features that are being considered while classification is done and still achieve a better accuracy levels, I applied hilbertification to the dataset and then used wavelets to localize the features thus giving us a denser set of features almost one-fourth of the original image. The results that I saw was not significantly lower when compared to the results obtained while considering all the features. Thus, it can be said that my method indeed captures the spatial relationships as proposed. Based on this, I have come to believe that the proposed method is not only viable, it also encodes some of very useful spatial information in a very dense space. This method can be extended extensively in future work by expanding to higher number of dimensions since it can efficiently encode temporal and spatial and even higher order dimensional data.<hr><ol class=footnotes-list><li id=fn-2><p>Falconer, Kenneth (2003). “Fractal Geometry: Mathematical Foundations and Applications.” John Wiley & Sons. xxv ISBN 0-470-84862-6. <a href=#fr-2-1>↩</a></p><li id=fn-1><p>von Melchner, Laurie & Pallas, Sarah & Sur, Mriganka (2000) “Visual Behaviour Mediated by Retinal Projections Directed to the Auditory Pathway.” Nature 404 871-6. 10.1038/35009102. <a href=#fr-1-1>↩</a></p><li id=fn-3><p>Boeing, G. (2016). “Visual Analysis of Nonlinear Dynamical Systems: Chaos, Fractals, Self-Similarity and the Limits of Prediction.” Systems 4 (4): 37. doi:10.3390/systems4040037. <a href=#fr-3-1>↩</a></p><li id=fn-7><p>Jaffer, Aubrey. “Color-Space Dimension Reduction.” Accessed November 19, 2018. https://people.csail.mit.edu/jaffer/CNS/PSFCDR. <a href=#fr-7-1>↩</a></p><li id=fn-5><p>Alex J. Smola, Bernhard Schölkopf. “A Tutorial on Support Vector Regression.” Statistics and Computing archive Volume 14 Issue 3, August 2004, p. 199-222. <a href=#fr-5-1>↩</a></p><li id=fn-6><p>Chui, Charles K. (1992). “An Introduction to Wavelets.” San Diego: Academic Press ISBN 0-12-174584-8. <a href=#fr-6-1>↩</a></p></ol></article><hr><nav id=post-nav><a class="post-nav-item post-nav-prev" href=https://theanig.github.io/blog/ner-lstm-cnn-icml/> <div class=nav-arrow>Previous</div> <span class=post-title>End-to-end Sequence-Labeling via Bi-directional LSTM CNNs CRF Tutorial</span> </a><a class="post-nav-item post-nav-next" href=https://theanig.github.io/blog/incremental-cooperative-rebalancing-kafka/> <div class=nav-arrow>Next</div> <span class=post-title>Understanding Cooperative Rebalancing in Apache Kafka</span> </a></nav><span class=hidden id=copy-code-text>Copy Code</span><span class=hidden id=search-index>https://theanig.github.io/search_index.en.json</span><span class=hidden id=more-matches-text>$MATCHES more matches</span></main><footer id=site-footer><nav><ul><li><a href=https://theanig.github.io/>About</a><li><a href=https://theanig.github.io/blog/>Blog</a></ul></nav><p>© TheAnig, 2025<ul id=socials><li><a rel=" me" href=https://discordapp.com/users/263024043391713281 title=Discord> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3EDiscord%3C/title%3E%3Cpath d='M20.317 4.3698a19.7913 19.7913 0 00-4.8851-1.5152.0741.0741 0 00-.0785.0371c-.211.3753-.4447.8648-.6083 1.2495-1.8447-.2762-3.68-.2762-5.4868 0-.1636-.3933-.4058-.8742-.6177-1.2495a.077.077 0 00-.0785-.037 19.7363 19.7363 0 00-4.8852 1.515.0699.0699 0 00-.0321.0277C.5334 9.0458-.319 13.5799.0992 18.0578a.0824.0824 0 00.0312.0561c2.0528 1.5076 4.0413 2.4228 5.9929 3.0294a.0777.0777 0 00.0842-.0276c.4616-.6304.8731-1.2952 1.226-1.9942a.076.076 0 00-.0416-.1057c-.6528-.2476-1.2743-.5495-1.8722-.8923a.077.077 0 01-.0076-.1277c.1258-.0943.2517-.1923.3718-.2914a.0743.0743 0 01.0776-.0105c3.9278 1.7933 8.18 1.7933 12.0614 0a.0739.0739 0 01.0785.0095c.1202.099.246.1981.3728.2924a.077.077 0 01-.0066.1276 12.2986 12.2986 0 01-1.873.8914.0766.0766 0 00-.0407.1067c.3604.698.7719 1.3628 1.225 1.9932a.076.076 0 00.0842.0286c1.961-.6067 3.9495-1.5219 6.0023-3.0294a.077.077 0 00.0313-.0552c.5004-5.177-.8382-9.6739-3.5485-13.6604a.061.061 0 00-.0312-.0286zM8.02 15.3312c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9555-2.4189 2.157-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.9555 2.4189-2.1569 2.4189zm7.9748 0c-1.1825 0-2.1569-1.0857-2.1569-2.419 0-1.3332.9554-2.4189 2.1569-2.4189 1.2108 0 2.1757 1.0952 2.1568 2.419 0 1.3332-.946 2.4189-2.1568 2.4189Z'/%3E%3C/svg%3E&#34)" class=icon></i> <span>Discord</span> </a><li><a rel=" me" href=https://github.com/TheAnig title=GitHub> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3EGitHub%3C/title%3E%3Cpath d='M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12'/%3E%3C/svg%3E&#34)" class=icon></i> <span>GitHub</span> </a><li><a rel=" me" href=https://www.instagram.com/theanig_gattokun/ title=Instagram> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3EInstagram%3C/title%3E%3Cpath d='M7.0301.084c-1.2768.0602-2.1487.264-2.911.5634-.7888.3075-1.4575.72-2.1228 1.3877-.6652.6677-1.075 1.3368-1.3802 2.127-.2954.7638-.4956 1.6365-.552 2.914-.0564 1.2775-.0689 1.6882-.0626 4.947.0062 3.2586.0206 3.6671.0825 4.9473.061 1.2765.264 2.1482.5635 2.9107.308.7889.72 1.4573 1.388 2.1228.6679.6655 1.3365 1.0743 2.1285 1.38.7632.295 1.6361.4961 2.9134.552 1.2773.056 1.6884.069 4.9462.0627 3.2578-.0062 3.668-.0207 4.9478-.0814 1.28-.0607 2.147-.2652 2.9098-.5633.7889-.3086 1.4578-.72 2.1228-1.3881.665-.6682 1.0745-1.3378 1.3795-2.1284.2957-.7632.4966-1.636.552-2.9124.056-1.2809.0692-1.6898.063-4.948-.0063-3.2583-.021-3.6668-.0817-4.9465-.0607-1.2797-.264-2.1487-.5633-2.9117-.3084-.7889-.72-1.4568-1.3876-2.1228C21.2982 1.33 20.628.9208 19.8378.6165 19.074.321 18.2017.1197 16.9244.0645 15.6471.0093 15.236-.005 11.977.0014 8.718.0076 8.31.0215 7.0301.0839m.1402 21.6932c-1.17-.0509-1.8053-.2453-2.2287-.408-.5606-.216-.96-.4771-1.3819-.895-.422-.4178-.6811-.8186-.9-1.378-.1644-.4234-.3624-1.058-.4171-2.228-.0595-1.2645-.072-1.6442-.079-4.848-.007-3.2037.0053-3.583.0607-4.848.05-1.169.2456-1.805.408-2.2282.216-.5613.4762-.96.895-1.3816.4188-.4217.8184-.6814 1.3783-.9003.423-.1651 1.0575-.3614 2.227-.4171 1.2655-.06 1.6447-.072 4.848-.079 3.2033-.007 3.5835.005 4.8495.0608 1.169.0508 1.8053.2445 2.228.408.5608.216.96.4754 1.3816.895.4217.4194.6816.8176.9005 1.3787.1653.4217.3617 1.056.4169 2.2263.0602 1.2655.0739 1.645.0796 4.848.0058 3.203-.0055 3.5834-.061 4.848-.051 1.17-.245 1.8055-.408 2.2294-.216.5604-.4763.96-.8954 1.3814-.419.4215-.8181.6811-1.3783.9-.4224.1649-1.0577.3617-2.2262.4174-1.2656.0595-1.6448.072-4.8493.079-3.2045.007-3.5825-.006-4.848-.0608M16.953 5.5864A1.44 1.44 0 1 0 18.39 4.144a1.44 1.44 0 0 0-1.437 1.4424M5.8385 12.012c.0067 3.4032 2.7706 6.1557 6.173 6.1493 3.4026-.0065 6.157-2.7701 6.1506-6.1733-.0065-3.4032-2.771-6.1565-6.174-6.1498-3.403.0067-6.156 2.771-6.1496 6.1738M8 12.0077a4 4 0 1 1 4.008 3.9921A3.9996 3.9996 0 0 1 8 12.0077'/%3E%3C/svg%3E&#34)" class=icon></i> <span>Instagram</span> </a><li><a rel=" me" href=https://www.linkedin.com/in/anirudh-ganesh95/ title=LinkedIn> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3ELinkedIn%3C/title%3E%3Cpath d='M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z'/%3E%3C/svg%3E&#34)" class=icon></i> <span>LinkedIn</span> </a><li><a rel=" me" href=https://steamcommunity.com/id/TheAnig/ title=Steam> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3ESteam%3C/title%3E%3Cpath d='M11.979 0C5.678 0 .511 4.86.022 11.037l6.432 2.658c.545-.371 1.203-.59 1.912-.59.063 0 .125.004.188.006l2.861-4.142V8.91c0-2.495 2.028-4.524 4.524-4.524 2.494 0 4.524 2.031 4.524 4.527s-2.03 4.525-4.524 4.525h-.105l-4.076 2.911c0 .052.004.105.004.159 0 1.875-1.515 3.396-3.39 3.396-1.635 0-3.016-1.173-3.331-2.727L.436 15.27C1.862 20.307 6.486 24 11.979 24c6.627 0 11.999-5.373 11.999-12S18.605 0 11.979 0zM7.54 18.21l-1.473-.61c.262.543.714.999 1.314 1.25 1.297.539 2.793-.076 3.332-1.375.263-.63.264-1.319.005-1.949s-.75-1.121-1.377-1.383c-.624-.26-1.29-.249-1.878-.03l1.523.63c.956.4 1.409 1.5 1.009 2.455-.397.957-1.497 1.41-2.454 1.012H7.54zm11.415-9.303c0-1.662-1.353-3.015-3.015-3.015-1.665 0-3.015 1.353-3.015 3.015 0 1.665 1.35 3.015 3.015 3.015 1.663 0 3.015-1.35 3.015-3.015zm-5.273-.005c0-1.252 1.013-2.266 2.265-2.266 1.249 0 2.266 1.014 2.266 2.266 0 1.251-1.017 2.265-2.266 2.265-1.253 0-2.265-1.014-2.265-2.265z'/%3E%3C/svg%3E&#34)" class=icon></i> <span>Steam</span> </a><li><a rel=" me" href=https://t.me/TheAnig title=Telegram> <i style="--icon:url(&#34data:image/svg+xml,%3Csvg role='img' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Ctitle%3ETelegram%3C/title%3E%3Cpath d='M11.944 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.056 0zm4.962 7.224c.1-.002.321.023.465.14a.506.506 0 0 1 .171.325c.016.093.036.306.02.472-.18 1.898-.962 6.502-1.36 8.627-.168.9-.499 1.201-.82 1.23-.696.065-1.225-.46-1.9-.902-1.056-.693-1.653-1.124-2.678-1.8-1.185-.78-.417-1.21.258-1.91.177-.184 3.247-2.977 3.307-3.23.007-.032.014-.15-.056-.212s-.174-.041-.249-.024c-.106.024-1.793 1.14-5.061 3.345-.48.33-.913.49-1.302.48-.428-.008-1.252-.241-1.865-.44-.752-.245-1.349-.374-1.297-.789.027-.216.325-.437.893-.663 3.498-1.524 5.83-2.529 6.998-3.014 3.332-1.386 4.025-1.627 4.476-1.635z'/%3E%3C/svg%3E&#34)" class=icon></i> <span>Telegram</span> </a></ul></footer>